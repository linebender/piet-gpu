// This is "kernel 2" (strokes) in a 4-kernel pipeline. It processes the stroke
// (polyline) items in the scene and generates a list of segments for each, for
// each tile.

#version 450
#extension GL_GOOGLE_include_directive : enable
#extension GL_KHR_shader_subgroup_ballot : enable
#extension GL_KHR_shader_subgroup_arithmetic : enable
#extension GL_KHR_shader_subgroup_shuffle : enable

layout(local_size_x = 32) in;

layout(set = 0, binding = 0) readonly buffer SceneBuf {
    uint[] scene;
};

layout(set = 0, binding = 1) buffer TilegroupBuf {
    uint[] tilegroup;
};

layout(set = 0, binding = 2) buffer SegmentBuf {
    uint[] segment;
};

layout(set = 0, binding = 3) buffer AllocBuf {
    uint alloc;
};

#include "scene.h"
#include "tilegroup.h"
#include "segment.h"

#include "setup.h"

// We should be able to use gl_SubgroupSize, but that's problematic.
#define SUBGROUP_SIZE 32

shared vec2 sh_start[SUBGROUP_SIZE];
shared vec2 sh_end[SUBGROUP_SIZE];
shared uint intersects[SUBGROUP_SIZE];

void main() {
    uint tile_ix = gl_GlobalInvocationID.y * WIDTH_IN_TILES + gl_GlobalInvocationID.x;
    uint tilegroup_ix = gl_GlobalInvocationID.y * WIDTH_IN_TILEGROUPS
        + (gl_GlobalInvocationID.x / TILEGROUP_WIDTH_TILES);
    float blockx0 = float((gl_GlobalInvocationID.x / TILEGROUP_WIDTH_TILES) * TILEGROUP_WIDTH_PX);
    vec2 xy0 = vec2(gl_GlobalInvocationID.xy) * vec2(TILE_WIDTH_PX, TILE_HEIGHT_PX);
    TileGroupRef stroke_start = TileGroupRef(tilegroup_ix * TILEGROUP_STRIDE + TILEGROUP_STROKE_START);
    uint stroke_n = tilegroup[stroke_start.offset >> 2];

    TileHeaderRef tile_header_ref = TileHeaderRef(tile_ix * TileHeader_size);
    if (stroke_n > 0) {
        ChunkRef chunk_ref = ChunkRef(stroke_start.offset + 4);
        Chunk chunk = Chunk_read(chunk_ref);
        InstanceRef stroke_ref = InstanceRef(chunk_ref.offset + Chunk_size);
        ItemHeaderRef item_header = ItemHeaderRef(atomicAdd(alloc, stroke_n * ItemHeader_size));
        TileHeader_write(tile_header_ref, TileHeader(stroke_n, item_header));
        SegChunkRef seg_chunk_ref = SegChunkRef(0);
        uint seg_limit = 0;

        // Iterate through items; chunk.chunk_n holds count remaining.
        while (true) {
            if (chunk.chunk_n == 0) {
                chunk_ref = chunk.next;
                if (chunk_ref.offset == 0) {
                    break;
                }
                chunk = Chunk_read(chunk_ref);
                stroke_ref = InstanceRef(chunk_ref.offset + Chunk_size);
            }
            Instance ins = Instance_read(stroke_ref);
            PietStrokePolyLine poly = PietItem_Poly_read(PietItemRef(ins.item_ref));
            float half_width = 0.5 * poly.width;
            uint n = poly.n_points - 1;

            uint chunk_n_segs = 0;
            for (uint j0 = 0; j0 < n; j0 += SUBGROUP_SIZE) {
                uint j = j0 + gl_LocalInvocationID.x;
                intersects[gl_LocalInvocationID.x] = 0;
                barrier();
                if (j < n) {
                    vec2 start = Point_read(Point_index(poly.points, j)).xy;
                    vec2 end = Point_read(Point_index(poly.points, j + 1)).xy;
                    sh_start[gl_SubgroupInvocationID] = start;
                    sh_end[gl_SubgroupInvocationID] = end;
                    float y0 = max(xy0.y - half_width, min(start.y, end.y));
                    float y1 = min(xy0.y + float(TILE_HEIGHT_PX) + half_width, max(start.y, end.y));
                    if (y0 < y1) {
                        float dy_inv = 1.0 / (end.y - start.y);
                        // Maybe fuzzy equality? There might also be a fancier way to do this
                        // with NaN behavior in min and max, but that sounds potentially flaky.
                        float u0 = start.y == end.y ? 0.0 : clamp((y0 - start.y) * dy_inv, 0.0, 1.0);
                        float u1 = start.y == end.y ? 1.0 : clamp((y1 - start.y) * dy_inv, 0.0, 1.0);
                        // maybe better to clamp after the mix (more precision)?
                        float x0 = mix(start.x, end.x, u0);
                        float x1 = mix(start.x, end.x, u1);
                        float xmin = max(min(x0, x1) - half_width - blockx0, 0.0);
                        float xmax = clamp(max(x0, x1) + half_width - blockx0, 0.0, float(TILEGROUP_WIDTH_PX));

                        uint x0i = uint(floor(xmin * (1.0 / TILE_WIDTH_PX)));
                        uint x1i = uint(ceil(xmax * (1.0 / TILE_WIDTH_PX)));
                        for (uint ix = x0i; ix < x1i; ix++) {
                            atomicOr(intersects[ix], 1 << gl_LocalInvocationID.x);
                        }
                    }
                }

                barrier();

                uint bitmask = intersects[gl_LocalInvocationID.x];
                while (bitmask != 0) {
                    uint k = findLSB(bitmask);
                    // Allocate a chunk if needed.
                    if (chunk_n_segs == 0) {
                        if (seg_chunk_ref.offset + 40 > seg_limit) {
                            seg_chunk_ref.offset = atomicAdd(alloc, SEG_CHUNK_ALLOC);
                            seg_limit = seg_chunk_ref.offset + SEG_CHUNK_ALLOC - Segment_size;
                        }
                        ItemHeader_write(item_header, ItemHeader(seg_chunk_ref));
                    } else if (seg_chunk_ref.offset + SegChunk_size + Segment_size * chunk_n_segs > seg_limit) {
                        uint new_chunk_ref = atomicAdd(alloc, SEG_CHUNK_ALLOC);
                        seg_limit = new_chunk_ref + SEG_CHUNK_ALLOC - Segment_size;
                        SegChunk_write(seg_chunk_ref, SegChunk(chunk_n_segs, SegChunkRef(new_chunk_ref)));
                        seg_chunk_ref.offset = new_chunk_ref;
                        chunk_n_segs = 0;
                    }
                    // Could clip the line here (maybe f16 repr)
                    vec2 start = sh_start[k];
                    vec2 end = sh_end[k];
                    Segment seg = Segment(start, end);
                    Segment_write(SegmentRef(seg_chunk_ref.offset + SegChunk_size + Segment_size * chunk_n_segs), seg);
                    chunk_n_segs++;

                    bitmask &= bitmask - 1; // clear bottom bit
                }
            }

            if (chunk_n_segs == 0) {
                ItemHeader_write(item_header, ItemHeader(SegChunkRef(0)));
            } else {
                SegChunk_write(seg_chunk_ref, SegChunk(chunk_n_segs, SegChunkRef(0)));
                seg_chunk_ref.offset += SegChunk_size + Segment_size * chunk_n_segs;
                chunk_n_segs = 0;
            }
            item_header.offset += ItemHeader_size;

            stroke_ref.offset += Instance_size;
            chunk.chunk_n--;
        }
    } else {
        // As an optimization, we could just write 0 for the size.
        TileHeader_write(tile_header_ref, TileHeader(stroke_n, ItemHeaderRef(0)));
    }
}
